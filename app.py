import streamlit as st
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import datetime
import re

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ä½ä¹‹æ±Ÿç«¶è‰‡AIäºˆæƒ³", page_icon="ğŸš¤")

# å®šæ•°ãƒ»è¨­å®š
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
SUPERSTARS = ["èŒ…åŸæ‚ ç´€", "é–¢æµ©å“‰", "å³°ç«œå¤ª", "æ± ç”°æµ©äºŒ", "æ¯’å³¶èª ", "æ¡ç”Ÿé †å¹³", "ç™½äº•è‹±æ²»", "é¦¬å ´è²´ä¹Ÿ", "çŸ³é‡è²´ä¹‹"]

def get_race_time_status(race_no):
    if race_no <= 4: return "ãƒ‡ã‚¤ãƒ¬ãƒ¼ã‚¹å¸¯"
    elif race_no <= 7: return "å¤•æ–¹ï¼ˆæ°—æ¸©å¤‰åŒ–æ³¨æ„ï¼‰"
    else: return "ãƒŠã‚¤ã‚¿ãƒ¼å¸¯"

@st.cache_data(ttl=300)
def get_full_race_data(place_cd, race_no, date_str):
    url_list = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={race_no}&jcd={place_cd}&hd={date_str}"
    url_info = f"https://www.boatrace.jp/owpc/pc/race/beforeinfo?rno={race_no}&jcd={place_cd}&hd={date_str}"
    try:
        resp_list = requests.get(url_list, headers=HEADERS); resp_list.encoding = resp_list.apparent_encoding
        soup_list = BeautifulSoup(resp_list.text, 'html.parser')
        tbodies = soup_list.find_all('tbody', class_='is-fs12')
    except: return None, "æ¥ç¶šã‚¨ãƒ©ãƒ¼", [], "ä¸æ˜"
    
    if not tbodies: return None, "ãƒ‡ãƒ¼ã‚¿ãªã—", [], "ä¸æ˜"

    racer_data = []
    for i, tbody in enumerate(tbodies[:6]):
        row_text = tbody.get_text()
        is_absent = "æ¬ å ´" in row_text or "ä¸å‚åŠ " in row_text
        name_div = tbody.find('div', class_='is-fs18')
        name_raw = name_div.get_text(strip=True).replace('\u3000', '') if name_div else "ä¸æ˜"
        name_with_mark = f"{name_raw}{'â˜…' if 'å¤§é˜ª' in row_text else ''}{'ã€SSã€‘' if any(s in name_raw for s in SUPERSTARS) else ''}"
        
        racer_class = "A1" if "A1" in row_text else ("A2" if "A2" in row_text else ("B1" if "B1" in row_text else "B2"))
        tds = tbody.find_all('td')
        vals = {"nation": "-", "local": "-", "motor": "-", "st": "-", "tenji": "-", "weight": "-"}
        
        if not is_absent and len(tds) >= 7:
            txt_all = tbody.get_text(separator=" ", strip=True)
            w_m = re.search(r'(\d{2})kg', txt_all)
            if w_m: vals["weight"] = w_m.group(1) + "kg"
            st_b = tds[3].get_text(separator="|", strip=True).split("|")
            for item in st_b: 
                if re.match(r'0\.\d{2}', item): vals["st"] = item
            
            nt = tds[4].get_text(separator="|", strip=True).split("|")
            if len(nt) > 0: vals["nation"] = re.search(r'(\d\.\d{2})', nt[0]).group(1) if re.search(r'(\d\.\d{2})', nt[0]) else "-"
            
            lt = tds[5].get_text(separator="|", strip=True).split("|")
            if len(lt) > 0: vals["local"] = re.search(r'(\d\.\d{2})', lt[0]).group(1) if re.search(r'(\d\.\d{2})', lt[0]) else "-"
            
            mt = tds[6].get_text(separator="|", strip=True).split("|")
            for item in mt:
                mn = re.search(r'(\d{2}\.\d{2})', item)
                if mn: 
                    v = float(mn.group(1))
                    if 10 <= v <= 99.9: vals["motor"] = f"{v}%"; break

        racer_data.append({"no": i+1, "name": name_with_mark, "class": racer_class, "weight": vals["weight"], "nation_rate": vals["nation"], "local_rate": vals["local"], "motor_rate": vals["motor"], "st": vals["st"], "tenji": vals["tenji"], "is_absent": is_absent})

    try:
        resp_info = requests.get(url_info, headers=HEADERS); resp_info.encoding = resp_info.apparent_encoding
        soup_info = BeautifulSoup(resp_info.text, 'html.parser')
        stab = "ã‚ã‚Š" if "å®‰å®šæ¿ä½¿ç”¨" in soup_info.get_text() else "ãªã—"
        wb = soup_info.find('div', class_='weather1_body')
        weather_text = "æƒ…å ±ãªã—"
        if wb:
            ft = wb.get_text(separator=" ", strip=True)
            tm = re.search(r'(\d+\.?\d*)\s*â„ƒ', ft); wm = re.search(r'é¢¨é€Ÿ.*?(\d+m)', ft)
            weather_text = f"æ°—æ¸©:{tm.group(1)+'â„ƒ' if tm else '-'}, é¢¨é€Ÿ:{wm.group(1) if wm else '-'}"
        
        course_list = []
        tables = soup_info.find_all('div', class_='table1')
        for table in tables:
            if "å±•ç¤ºã‚¿ã‚¤ãƒ " in table.get_text():
                rows = table.find_all('tbody')
                for i, row in enumerate(rows[:6]):
                    if i < len(racer_data) and len(row.find_all('td')) >= 6:
                        tt = row.find_all('td')[4].get_text(strip=True)
                        if re.match(r'\d\.\d{2}', tt): racer_data[i]['tenji'] = tt
            if "ã‚¹ã‚¿ãƒ¼ãƒˆå±•ç¤º" in table.get_text():
                for row in table.find_all('tbody'):
                    img = row.find('img', class_=lambda x: x and x.startswith('is-boatColor'))
                    if img: course_list.append(img.get('class')[0].replace('is-boatColor', ''))
    except: weather_text="å–å¾—ã‚¨ãƒ©ãƒ¼"; course_list=[]; stab="-"
    return racer_data, weather_text, course_list, stab

# UI
st.title("ğŸš¤ ä½ä¹‹æ±Ÿç«¶è‰‡ AIäºˆæƒ³")
st.markdown("å®Œå…¨ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆã‚¤ãƒ³å´©å£Šãƒ»SSç‰¹ä¾‹ãƒ»å…¨å›½å®Ÿç¸¾ï¼‰æ­è¼‰ç‰ˆ")

with st.sidebar:
    st.header("ãƒ¬ãƒ¼ã‚¹è¨­å®š")
    date_input = st.date_input("æ—¥ä»˜é¸æŠ", datetime.date.today())
    race_no = st.slider("ãƒ¬ãƒ¼ã‚¹ç•ªå·", 1, 12, 12)

if st.button("AIäºˆæƒ³ã‚’é–‹å§‹ã™ã‚‹", type="primary"):
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    s_date = date_input.strftime('%Y%m%d'); time_status = get_race_time_status(race_no)
    st.info(f"ğŸ“¡ ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­... ä½ä¹‹æ±Ÿ {s_date} {race_no}R")
    racers, weather, courses, stab = get_full_race_data("12", race_no, s_date)
    
    if racers:
        course_text = " -> ".join(courses) if courses else "æ ãªã‚Š (æ¨å®š)"
        st.subheader("ğŸ“Š å‡ºèµ°è¡¨"); st.write(f"ç’°å¢ƒ: {weather} / å®‰å®šæ¿: {stab} / é€²å…¥: {course_text}")
        table_data = []; table_str = "| æ  | é¸æ‰‹(â˜…å¤§é˜ª/ã€SSã€‘) | ç´š | å…¨å›½ç‡ | å½“åœ°ç‡ | æ©Ÿ2é€£ | ST | å±•ç¤º |\n|---|---|---|---|---|---|---|---|\n"
        for r in racers:
            if not r['is_absent']:
                table_data.append({"æ ": r['no'], "é¸æ‰‹": r['name'], "ç´š": r['class'], "å…¨å›½": r['nation_rate'], "å½“åœ°": r['local_rate'], "æ©Ÿ2é€£": r['motor_rate'], "ST": r['st'], "å±•ç¤º": r['tenji']})
                table_str += f"| {r['no']} | {r['name']} | {r['class']} | {r['nation_rate']} | {r['local_rate']} | {r['motor_rate']} | {r['st']} | {r['tenji']} |\n"
        st.table(table_data)
        
        st.subheader("ğŸ§  Gemini AIã®çµè«–")
        with st.spinner("AIæ€è€ƒä¸­..."):
            prompt = f"""
            ã‚ãªãŸã¯ãƒœãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹ä½ä¹‹æ±Ÿã®å°‚é–€åˆ†æAIã§ã™ã€‚ä»¥ä¸‹ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãäºˆæƒ³ã›ã‚ˆã€‚
            ã€æ¡ä»¶ã€‘ä½ä¹‹æ±Ÿ{race_no}R({time_status}) å¤©å€™:{weather} é€²å…¥:{course_text}
            ã€å‡ºèµ°è¡¨ã€‘\n{table_str}
            ã€æ€è€ƒãƒ­ã‚¸ãƒƒã‚¯ã€‘
            1.å…¨å›½ç‡é‡è¦–:å½“åœ°ç‡ä½ãã¦ã‚‚å…¨å›½ç‡6.00ä»¥ä¸ŠAç´šã¯åˆ‡ã‚‹ãªã€‚
            2.ã‚¤ãƒ³å´©å£Š:1å·è‰‡Bç´šorå…¨å›½ç‡5.5ä»¥ä¸‹&æ©ŸåŠ›å¼±ãªã‚‰ã‚»ãƒ³ã‚¿ãƒ¼Aç´šé ­æœ¬ç·šã€‚
            3.4ã‚«ãƒ‰ã¾ãã‚Š:4å·è‰‡Aç´šSTæ—©ãªã‚‰4-5è­¦æˆ’ã€‚
            4.SSç‰¹ä¾‹:ã€SSã€‘é¸æ‰‹ã¯å¿…ãš3ç€å†…ã€‚
            ã€å‡ºåŠ›å½¢å¼ã€‘
            ### ğŸ¯ æœ€çµ‚çµè«–
            | ç‹™ã„ | è²·ã„ç›® (3é€£å˜) |
            | :--- | :--- |
            | **ã€æœ¬ç·šã€‘** | **... (â€»åšã‚)** |
            | **ã€æŠ‘ãˆã€‘** | **...** |
            | **ã€ ç©´ ã€‘** | **...** |
            **åˆè¨ˆ: Xç‚¹**
            **æ ¹æ‹ **: (1è¡Œã§)
            """
            try:
                genai.configure(api_key=api_key); model = genai.GenerativeModel('gemini-2.0-flash')
                res = model.generate_content(prompt); st.markdown(res.text)
            except Exception as e: st.error(f"AIã‚¨ãƒ©ãƒ¼: {e}")
    else: st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
